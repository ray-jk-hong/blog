<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>内存虚拟化 | ray.jk.hong</title><meta name="author" content="ray.jk.hong"><meta name="copyright" content="ray.jk.hong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="介绍主要内存虚拟化相关介绍，会涉及部分KVM相关内容，但这里不涉及KVM的具体软件架构。内存的虚拟化，包含以下两个方向的内存访问。一. VM访问PM物理内存VM的os访问PM物理内存，主要有两种方式。  软件的:影子页表  硬件的: Intel的EPT, AMD的NPT, ARM的SMMU Stage-2支持  二. PM访问VM的内存。  没有硬件支持：通过vfio_pin_pags等方式，在P">
<meta property="og:type" content="article">
<meta property="og:title" content="内存虚拟化">
<meta property="og:url" content="https://ray-jk-hong.github.io/2025/05/16/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/index.html">
<meta property="og:site_name" content="ray.jk.hong">
<meta property="og:description" content="介绍主要内存虚拟化相关介绍，会涉及部分KVM相关内容，但这里不涉及KVM的具体软件架构。内存的虚拟化，包含以下两个方向的内存访问。一. VM访问PM物理内存VM的os访问PM物理内存，主要有两种方式。  软件的:影子页表  硬件的: Intel的EPT, AMD的NPT, ARM的SMMU Stage-2支持  二. PM访问VM的内存。  没有硬件支持：通过vfio_pin_pags等方式，在P">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ray-jk-hong.github.io/img/butterfly-icon.png">
<meta property="article:published_time" content="2025-05-16T11:32:55.167Z">
<meta property="article:modified_time" content="2025-05-31T02:14:32.004Z">
<meta property="article:author" content="ray.jk.hong">
<meta property="article:tag" content="虚拟化">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ray-jk-hong.github.io/img/butterfly-icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "内存虚拟化",
  "url": "https://ray-jk-hong.github.io/2025/05/16/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/",
  "image": "https://ray-jk-hong.github.io/img/butterfly-icon.png",
  "datePublished": "2025-05-16T11:32:55.167Z",
  "dateModified": "2025-05-31T02:14:32.004Z",
  "author": [
    {
      "@type": "Person",
      "name": "ray.jk.hong",
      "url": "https://ray-jk-hong.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/blog/img/favicon.png"><link rel="canonical" href="https://ray-jk-hong.github.io/2025/05/16/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/blog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/blog/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '内存虚拟化',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script src="/js/bandev.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blog/"></a><a class="nav-page-title" href="/blog/"><span class="site-name">内存虚拟化</span></a></span><div id="menus"></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">内存虚拟化</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-categories"><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/blog/categories/linux/">linux</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>主要内存虚拟化相关介绍，会涉及部分KVM相关内容，但这里不涉及KVM的具体软件架构。<br>内存的虚拟化，包含以下两个方向的内存访问。<br>一. VM访问PM物理内存<br>VM的os访问PM物理内存，主要有两种方式。</p>
<ol>
<li>软件的:影子页表 </li>
<li>硬件的: Intel的EPT, AMD的NPT, ARM的SMMU Stage-2支持</li>
</ol>
<p>二. PM访问VM的内存。</p>
<ol>
<li>没有硬件支持：通过vfio_pin_pags等方式，在PM侧访问VM内存。（PM在拿到VM使用的page之后，做dma并进行访问）。</li>
<li>有硬件支持：VM的iova地址可以直接通过PM的DMA访问。</li>
</ol>
<p>上述的场景，其实还需要分支持VHE与否。这一篇先以不支持VHE的场景说明。</p>
<h2 id="VM访问PM物理内存"><a href="#VM访问PM物理内存" class="headerlink" title="VM访问PM物理内存"></a>VM访问PM物理内存</h2><h3 id="硬件支持"><a href="#硬件支持" class="headerlink" title="硬件支持"></a>硬件支持</h3><p>在有硬件支持的场景，Guest OS中的虚拟地址（GVA），需要经过多重的地址转换，才能真正访问到真正保存内容的物理地址。</p>
<img src="/blog/2025/05/16/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/%E6%95%B4%E4%BD%93%E8%AE%BF%E9%97%AE%E6%B5%81%E7%A8%8B.png" class="" title="图片描述">

<p>如上图中红色线条就是地址转换的流程。<br>举一个简单例子，在Guest 内malloc一段地址给g_var这个变量并通过memset访问的时候，就需要通过GVA-&gt;GPA-&gt;HPA等多个步骤才能访问到。<br>下面我们一条一条看一下每一步转换是怎么实现的。</p>
<h3 id="GVA-GPA"><a href="#GVA-GPA" class="headerlink" title="GVA-&gt;GPA"></a>GVA-&gt;GPA</h3><p>GVA-&gt;GPA的地址转换，跟物理机是完全一样的，就是根据TTBRx_EL1寄存器找到页表基地址，再根据页表一级一级翻译。由于全虚拟化标榜的是不修改内核，所以这个建页表的流程和配置寄存器的行为是跟PM完全一致的。<br>物理机配置页表寄存器参考：<a href="https://ray-jk-hong.github.io/blog/2025/04/16/arch/Arm-mmu/">https://ray-jk-hong.github.io/blog/2025/04/16/arch/Arm-mmu/</a></p>
<p>乍看之下，好像都明白了，但仔细想想，这里还是有很多疑问的。例如</p>
<ol>
<li>VM的Linux内核在启动的时候需要将页表基地址配置到TTBRx_EL1寄存器，而且还会调用建页表的接口，将GVA-&gt;GPA的页表建好。但TTBRx_EL1寄存器不区分PM还是VM，VM把这个寄存器改了，那PM的地址翻译都不可用了。KVM是怎么解决这个问题的呢？<br>答案是KVM保存了VM&#x2F;PM的TTBRx_EL1的值（这里只是拿TTBRx_EL1来举例，其实还有很多寄存器，还是看上面的参考链接），并在某个CPU在PM-&gt;VM, VM-&gt;PM切换的时候进行切换的方式解决了这个问题。<br>以下代码显示了在某个CPU上，CPU从执行PM代码，跳转到执行VM的过程中，KVM是怎么切换TTBRx_EL1的值的（__sysreg_save_state_nvhe&#x2F;__sysreg_restore_state_nvhe函数中就有读取或者写入TTBRx_EL1寄存器的内容）。</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* arch/arm64/kvm/hyp/nvhe/switch.c */</span></span><br><span class="line"><span class="comment">/* Switch to the guest for legacy non-VHE systems */</span></span><br><span class="line"><span class="type">int</span> __kvm_vcpu_run(<span class="keyword">struct</span> kvm_vcpu *vcpu)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">kvm_cpu_context</span> *<span class="title">host_ctxt</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">kvm_cpu_context</span> *<span class="title">guest_ctxt</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取上下文指针</span></span><br><span class="line">	host_ctxt = &amp;this_cpu_ptr(&amp;kvm_host_data)-&gt;host_ctxt;</span><br><span class="line">	host_ctxt-&gt;__hyp_running_vcpu = vcpu;</span><br><span class="line">	guest_ctxt = &amp;vcpu-&gt;arch.ctxt;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 保存主机上下文（包括所有EL1系统寄存器）</span></span><br><span class="line">    __sysreg_save_state_nvhe(host_ctxt);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 恢复客户机上下文（包括TTBR1_EL1等）</span></span><br><span class="line">    __sysreg_restore_state_nvhe(guest_ctxt);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 3. 设置其他虚拟化控制寄存器</span></span><br><span class="line">    write_sysreg(vcpu-&gt;arch.hcr_el2, hcr_el2);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 4. 确保所有寄存器写入生效</span></span><br><span class="line">    isb();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 5. 执行客户机代码...</span></span><br><span class="line">	<span class="keyword">do</span> &#123;</span><br><span class="line">		<span class="comment">/* Jump in the fire! */</span></span><br><span class="line">		exit_code = __guest_enter(vcpu);</span><br><span class="line"></span><br><span class="line">		<span class="comment">/* And we&#x27;re baaack! */</span></span><br><span class="line">	&#125; <span class="keyword">while</span> (fixup_guest_exit(vcpu, &amp;exit_code));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 6. 客户机退出后，再次保存客户机上下文</span></span><br><span class="line">    __sysreg_save_state_nvhe(guest_ctxt);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 7. 恢复主机上下文（包括TTBR1_EL1等）</span></span><br><span class="line">    __sysreg_restore_state_nvhe(host_ctxt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>VM的Linux内核在配置TTBRx_EL1的时候，KVM是怎么感知VM在配置这个寄存器并保存的？<br>HCR_EL2寄存器可以设置，在VM的Linux内核（VM的内核也是在EL1级别执行）访问地址转换相关寄存器的时候，从EL1 trap到EL2并通过异常寄存器知道是在访问哪个寄存器。<br>下面只看一下HCR_EL2寄存器主要相关的设置（详细的需要补充）。<br>(1) TVM[26]: 写1时，在EL1写TTBRx_EL1等寄存器的时候，会被trap到EL2级别。<br>(2) TRVM[30]: 写1时，在EL1读TTBRx_EL1等寄存器的时候，会被trap到EL2级别<br>上述这些寄存器的访问（通过MSR, MRS等命令）的时候，该命令触发trap并被KVM拦截。<br>VM的Linux设置的寄存器内容，就会被保存在<code>struct kvm_vcpu_arch</code>结构体中，然后在PM-&gt;VM， VM-&gt;PM切换的时候被设置到真正的寄存器中。</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* arch/arm64/include/asm/kvm_host.h */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">kvm_vcpu_arch</span> &#123;</span></span><br><span class="line">    ....</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>被trap之后，将内容保存到<code>struct kvm_vcpu_arch</code>中的函数如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* arch/arm64/kvm/sys_regs.c */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">kvm_handle_sys_reg</span><span class="params">(<span class="keyword">struct</span> kvm_vcpu *vcpu)</span></span><br><span class="line">&#123;</span><br><span class="line">    ....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="GPA-HPA"><a href="#GPA-HPA" class="headerlink" title="GPA-&gt;HPA"></a>GPA-&gt;HPA</h3><p>这部分转换，就是所谓的MMU的Stage-2转换了（注意SMMU&#x2F;IOMMU其实也都有Stage-1&#x2F;Stage-2转换，不要混淆）。</p>
<p>在上一部分，VM中的Linux内核在KVM配合下已经配置了TTBRx_EL1等寄存器，在访问的时候已经是可以做GVA-&gt;GPA转换了。但GPA其实还没有在PM中有对应的物理地址可以访问。那这种情况下KVM又是出么处理，并最终建好Stage-2页表的呢？</p>
<p>完成Stage-2页表创建有一个前提就是Qemu在启动VM的时候需要使用<code>KVM_SET_USER_MEMORY_REGION</code>将GPA段和HVA段的对应关系注册给KVM。因为在下面的异常流程中，需要使用到。</p>
<ol>
<li>在VM中通过GVA-&gt;GPA转换完地址之后访问会触发异常，进而触发vm_exit。异常信息会被记录在<code>ESR_EL2</code>&#x2F;<code>HPFAR_EL2</code></li>
<li>在KVM代码中，会通过解析<code>ESR_EL2</code>&#x2F;<code>HPFAR_EL2</code>调用不同的处理函数，例如内存访问对应的回调函数如下：</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// arch/arm64/kvm/handle_exit.c</span></span><br><span class="line"><span class="type">static</span> exit_handle_fn arm_exit_handlers[] = &#123;</span><br><span class="line">	[ESR_ELx_EC_IABT_LOW]	= kvm_handle_guest_abort,</span><br><span class="line">	[ESR_ELx_EC_DABT_LOW]	= kvm_handle_guest_abort,    </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>在<code>kvm_handle_guest_abort</code>-&gt;<code>user_mem_abort</code>函数中，就会根据GPA的GFN， HPA的PFN进行页表创建（在此过程中会在PM中申请内存）。</p>
<img src="/blog/2025/05/16/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%9C%B0%E5%9D%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png" class="" title="图片描述">

<p>上面就是从网上找的一个<code>kvm_handle_guest_abort</code>函数的流程，懒得画了先拿过来凑合看一下。</p>
<p>Stage-2的页表创建过程还需要再详细补充：</p>
<ol>
<li>涉及的VTTBRx_EL寄存器也要补充</li>
<li>Stage-2的页表格式好像也跟Stage-1的格式或者内容稍有区别，也要补充。</li>
</ol>
<p>讲到这里，VM中的程序，怎么一步一步通过翻译地址访问到PM的地址就大概知道怎么处理的了。</p>
<h2 id="PM访问VM的内存"><a href="#PM访问VM的内存" class="headerlink" title="PM访问VM的内存"></a>PM访问VM的内存</h2><h3 id="直接访问VM"><a href="#直接访问VM" class="headerlink" title="直接访问VM"></a>直接访问VM</h3><p>Qemu在VM启动的时候，通过mmap申请一段HVA，并将VM的GPA地址段通过注册给KVM_SET_USER_MEMORY_REGION，KVM中就会保留一段一段的GPA&lt;-&gt;HVA的对应关系。当我们拿到VM的GPA的时候，我们就可以通过其找到VM进程对应的HVA并将其翻译成HPA。</p>
<p>相关代码可以参考<code>struct page *gfn_to_page(struct kvm *kvm, gfn_t gfn)</code>。</p>
<h3 id="DMA访问"><a href="#DMA访问" class="headerlink" title="DMA访问"></a>DMA访问</h3><h4 id="通过VM的IOVA访问"><a href="#通过VM的IOVA访问" class="headerlink" title="通过VM的IOVA访问"></a>通过VM的IOVA访问</h4><p>在qemu的<code>vfio</code>启动的时候，会调用<code>VFIO_CHECK_EXTENSION</code>获取内核支持的<code>iommu</code>类型。获取的时候是按照<code>VFIO_TYPE1v2_IOMMU</code>, <code>VFIO_TYPE1_IOMMU</code>等顺序获取的，内核态的vfio也是在<code>VFIO_TYPE1v2_IOMMU</code>的时候就直接返回了1表示支持。所以默认情况下，qemu中的vfio使用的iommu类型就是<code>VFIO_TYPE1v2_IOMMU</code>，而这个类型是只支持Stage-1类型的。（当前没有看到Stage-1 + Stage-2类型的<code>VFIO_TYPE1_NESTING_IOMMU</code>，这种形态后续再补充）。</p>
<img src="/blog/2025/05/16/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/VFIO_DMA_MAP.png" class="" title="图片描述">

<p>如上图所示，在VM内核做dma map的时候，qemu会感知到变化捕获VM中的iova与gpa。此时qemu将gpa转成hva（在qemu初始化的时候准备好的hva与gpa之间的关系了）。之后就会调用vfio的ioctl, 通过<code>VFIO_IOMMU_MAP_DMA</code>命令，将VM中的iova地址和hva地址传给PM内核的vfio驱动。<br>在vfio驱动内hva可以转成hpa， 再调用iommu map接口就可以映射VM内的iova与hpa之间的页表。<br>那在PM下，拿到VM的iova地址之后，因为VM的iova与PM的hpa已经建好页表，我们就可以使用DMA搬数据。</p>
<p><code>VFIO_IOMMU_MAP_DMA</code>命令传的结构体如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">vfio_iommu_type1_dma_map</span> &#123;</span></span><br><span class="line">    __u32 argsz;</span><br><span class="line">    __u32 flags;</span><br><span class="line">    __u64 vaddr;    <span class="comment">/* 用户空间虚拟地址 (HVA) */</span></span><br><span class="line">    __u64 iova;     <span class="comment">/* I/O虚拟地址 - 但QEMU传入的是GPA */</span></span><br><span class="line">    __u64 size;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>下面简单看一下qemu关节回调并调用到<code>VFIO_IOMMU_MAP_DMA</code>的代码：（这部分会在qemu内存模型中详细讲）</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vfio_listener_region_add</span><br><span class="line">    -&gt;iommu_notifier_init(xx, vfio_iommu_map_notify, xx)</span><br></pre></td></tr></table></figure>

<p>在VM中Linux OS进行DMA map的时候，在如下流程中，会注册hva和iova给vfio，vfio进而在内核态将把iova和hpa映射给iommu。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vfio_iommu_map_notify</span><br><span class="line">    -&gt;vfio_dma_map</span><br><span class="line">        -&gt;ioctl(xx, VFIO_IOMMU_MAP_DMA)</span><br></pre></td></tr></table></figure>

<p>那qemu又是怎么知道VM中的Linux内核在做dma_map_single等操作的呢？<br>在Guest中，virtio-iommu作为IOMMU设备呈现给Linux内核<br>当Guest Linux调用dma_map_single时，会通过IOMMU驱动将映射请求发送到virtio-iommu设备<br>virtio-iommu设备通过virtqueue机制将这些映射请求传递给QEMU<br>QEMU实现的virtio-iommu后端会处理这些请求，完成实际的地址转换和权限控制<br>Guest OS中的DMA映射操作被转化为virtio队列中的命令，通过共享内存区域传递给QEMU。QEMU捕获这些命令后，代表Guest执行真正的IOMMU操作，实现Guest物理地址到主机物理地址的映射。<br>这种机制使得Guest中的设备可以使用DMA，同时保持内存隔离和安全性，因为所有DMA访问都经过QEMU的控制和转换。<br>所以上面的图应该增加一个Guest os的virtio-iommu。</p>
<img src="/blog/2025/05/16/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/VFIO_DMA_MAP-1.png" class="" title="图片描述">

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://www.virtualopensystems.com/en/virtualization/">https://www.virtualopensystems.com/en/virtualization/</a></p>
<p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/ka005372/latest/">https://developer.arm.com/documentation/ka005372/latest/</a></p>
<p><a target="_blank" rel="noopener" href="https://patchwork.kernel.org/project/kvm/patch/1580300216-86172-3-git-send-email-yi.l.liu@intel.com/#23151005">https://patchwork.kernel.org/project/kvm/patch/1580300216-86172-3-git-send-email-yi.l.liu@intel.com/#23151005</a></p>
<p>这个好<br><a target="_blank" rel="noopener" href="https://pages.cs.wisc.edu/~basu/isca_iommu_tutorial/index.htm">https://pages.cs.wisc.edu/~basu/isca_iommu_tutorial/index.htm</a></p>
<p>chrome-extension:&#x2F;&#x2F;efaidnbmnnnibpcajpcglclefindmkaj&#x2F;<a target="_blank" rel="noopener" href="https://events19.lfasiallc.com/wp-content/uploads/2017/11//Shared-Virtual-Memory-in-KVM_Yi-Liu.pdf">https://events19.lfasiallc.com/wp-content/uploads/2017/11//Shared-Virtual-Memory-in-KVM_Yi-Liu.pdf</a></p>
<p>chrome-extension:&#x2F;&#x2F;efaidnbmnnnibpcajpcglclefindmkaj&#x2F;<a target="_blank" rel="noopener" href="https://events19.linuxfoundation.org/wp-content/uploads/2017/12/Hardware-Assisted-Mediated-Pass-Through-with-VFIO-Kevin-Tian-Intel.pdf">https://events19.linuxfoundation.org/wp-content/uploads/2017/12/Hardware-Assisted-Mediated-Pass-Through-with-VFIO-Kevin-Tian-Intel.pdf</a></p>
<p>chrome-extension:&#x2F;&#x2F;efaidnbmnnnibpcajpcglclefindmkaj&#x2F;<a target="_blank" rel="noopener" href="https://events19.linuxfoundation.cn/wp-content/uploads/2017/11/Shared-Virtual-Memory-in-KVM_Yi-Liu.pdf">https://events19.linuxfoundation.cn/wp-content/uploads/2017/11/Shared-Virtual-Memory-in-KVM_Yi-Liu.pdf</a></p>
<p><a target="_blank" rel="noopener" href="https://www.google.com/search?q=iommu+nested+translation&sca_esv=02467373b682e586&ei=FpIQaMrOHcvW1e8P-6jg8Ao&start=10&sa=N&sstk=Af40H4VEMiaVzSnPueG5dqs1tBgXHytF3lXY3AI6PRJVXLmH1lD-LAQsxlW7C6iCauu-q0eEMA4AVTDBjmGnzaOxqOxVVOGGOx1D_A&ved=2ahUKEwjKsf7I7fyMAxVLa_UHHXsUGK4Q8tMDegQIChAE&biw=1864&bih=614&dpr=1">https://www.google.com/search?q=iommu+nested+translation&amp;sca_esv=02467373b682e586&amp;ei=FpIQaMrOHcvW1e8P-6jg8Ao&amp;start=10&amp;sa=N&amp;sstk=Af40H4VEMiaVzSnPueG5dqs1tBgXHytF3lXY3AI6PRJVXLmH1lD-LAQsxlW7C6iCauu-q0eEMA4AVTDBjmGnzaOxqOxVVOGGOx1D_A&amp;ved=2ahUKEwjKsf7I7fyMAxVLa_UHHXsUGK4Q8tMDegQIChAE&amp;biw=1864&amp;bih=614&amp;dpr=1</a></p>
<p>谷歌：Shared Virtual Memory </p>
<p><a target="_blank" rel="noopener" href="https://docs.kernel.org/6.3/x86/sva.html">https://docs.kernel.org/6.3/x86/sva.html</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://ray-jk-hong.github.io">ray.jk.hong</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://ray-jk-hong.github.io/2025/05/16/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/">https://ray-jk-hong.github.io/2025/05/16/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://ray-jk-hong.github.io" target="_blank">ray.jk.hong</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/blog/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/">虚拟化</a></div><div class="post-share"><div class="social-share" data-image="/blog/img/butterfly-icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blog/2025/05/16/linux/Debug/ftrace/ftrace/" title="ftrace"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">ftrace</div></div><div class="info-2"><div class="info-item-1">原理  编译阶段：gcc增加-pg选项ftrace支持动态trace，既可以跟踪内核和模块中任意的全局函数。编译阶段增加-pg到gcc编译选项中，会在每个函数的开始增加一个stub，这样可以在需要的时候控制函数跳转到指定的代码中去。 123456(gdb) disassemble tcp_sendmsgDump of assembler code for function tcp_sendmsg:	0xffff000008c1234 	&lt;+0&gt;: 	stp x29, 0x30, [sp, #-49]!	....	....	0xffff000008c1256	&lt;+56&gt;:	bl 0xffff00000809cfe8	&lt;_mcount&gt; 1234(gdb) disassemble _mcountDump of assembler code for function _mcount:	0xffff00000809cfe8 &lt;+0&gt;:	retEnd of assembler...</div></div></div></a><a class="pagination-related" href="/blog/2025/05/16/linux/%E9%A9%B1%E5%8A%A8/Smmu/iommu%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84/" title="iommu软件架构"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">iommu软件架构</div></div><div class="info-2"><div class="info-item-1">软件层次以下以arm-smmu-v3为例，先大致看一下软件层次。软件层次大概分为两个部分，一个是IOMMU，另一个是ARM SMMU部分。 IOMMU是Linux给各个不同的芯片和架构提供的通用的架构。   ARM SMMU部分就是ARM架构为了实现SMMU功能提供的架构。   这两个软件层次，这里先不解释。先往下看内容，看完一步再回来看一下为什么这么设计会好一点。 DTS配置DTS主要分两个，一个是arm-smmu-v3的配置和使用arm-smmu-v3的驱动的dts配置。 1. arm-smmu-v3 DTS配置假设我们默认使用arm-smmu-v3.c文件（很多厂商都有自己的），则DTS配置如下。 1234567891011121314151617181920212223242526272829303132333435363738iommu0@2b400000 &#123;        compatible = &quot;arm,smmu-v3&quot;;        reg = &lt;0x2b400000 0x20000&gt;;       ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/blog/2025/04/26/linux/%E8%99%9A%E6%8B%9F%E5%8C%96/mmio%E8%99%9A%E6%8B%9F%E5%8C%96/" title="mmio虚拟化"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-26</div><div class="info-item-2">mmio虚拟化</div></div><div class="info-2"><div class="info-item-1">在看怎么实现mmio虚拟化之前，可以看一下内存虚拟化。VM内的OS在访问外设的时候跟访问HPA地址是一样的、也是通过Stage-1转GVA到GPA(IPA)、再通过Stage-2转IPA到HPA。   如上图、介绍了两种mmio访问方式、assigned peripheral和virtual peripheral。assigned peripheral是已经被映射到VM内的真实的外设（作为例子，可以将sr-iov将vf配置空间透给VM直接访问的例子加到这里，后续补充）。这种外设通过Stage-1 + Stage-2是可以直接访问外设寄存器的。virtual...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blog/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">ray.jk.hong</div><div class="author-info-description"></div><div class="site-data"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ray-jk-hong"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VM%E8%AE%BF%E9%97%AEPM%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98"><span class="toc-number">2.</span> <span class="toc-text">VM访问PM物理内存</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E6%94%AF%E6%8C%81"><span class="toc-number">2.1.</span> <span class="toc-text">硬件支持</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GVA-GPA"><span class="toc-number">2.2.</span> <span class="toc-text">GVA-&gt;GPA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPA-HPA"><span class="toc-number">2.3.</span> <span class="toc-text">GPA-&gt;HPA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PM%E8%AE%BF%E9%97%AEVM%E7%9A%84%E5%86%85%E5%AD%98"><span class="toc-number">3.</span> <span class="toc-text">PM访问VM的内存</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AEVM"><span class="toc-number">3.1.</span> <span class="toc-text">直接访问VM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DMA%E8%AE%BF%E9%97%AE"><span class="toc-number">3.2.</span> <span class="toc-text">DMA访问</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87VM%E7%9A%84IOVA%E8%AE%BF%E9%97%AE"><span class="toc-number">3.2.1.</span> <span class="toc-text">通过VM的IOVA访问</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">4.</span> <span class="toc-text">参考</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blog/js/utils.js"></script><script src="/blog/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>